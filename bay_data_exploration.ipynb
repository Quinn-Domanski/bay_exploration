{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e95661b-b41e-498f-aa26-b25c21a2d83c",
   "metadata": {},
   "source": [
    "# Chesapeake Bay Data Exploration\n",
    "\n",
    "By: Quinn Domanski\n",
    "\n",
    "## What's going on with the Chesapeake Bay?\n",
    "\n",
    "### Question:\n",
    "\n",
    "Since 1984, sites have been set up around the bay to monitor multiple paramters that could effect the health of The Chesapeake Bay. The health of The Chesapeake Bay refers to the Bay's ability to support diverse aquatic life, through it's intricate natural systems. Some of these parameters include, Temperature ( &deg;C ), Salinity (ppt),  and pH. One important paramter is Total Nitrogen (TN) and Nitrate/Nitrite (NO23), as both of these can cause major problems to the health of the Chesapeake Bay, with an excess of these paramters causing massive algal blooms which consume oxygen creating dead zones (areas with low dissolved oxygen (DO) where marine life can't survive). We want to know:\n",
    "\n",
    "**What causes increased levels of Total Nitrogen and Nitrate/Nitrite?**\n",
    "\n",
    "In this notebook, we analyze parameters that could be correlated to Total Nitrogen and Nitrate/Nitrite, to identify if we can find a trend that causes these to increase. By detecting these patterns we hope to find out what could be causing high levels of both of these in the Bay. This leads us to an overarching question of:\n",
    "\n",
    "**Can we find a correlation between any of the paramters that are recorded, including geographic features and nutrient levels?**\n",
    "\n",
    "Dataset Used:\n",
    "\n",
    "* https://eyesonthebay.dnr.maryland.gov/bay_cond/LongTermData.cfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a50be36-db42-4fe3-a5e5-a9a1baf8c361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ed0e45-cc67-41d7-bc7f-7d073a6a3abe",
   "metadata": {},
   "source": [
    "### Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29a733bd-90d7-42ab-9453-b8ecaa418972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11107/2836962627.py:17: DtypeWarning: Columns (26,27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  all_data_original = pd.read_csv(\"data/all_data.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>MonitoringStation</th>\n",
       "      <th>EventId</th>\n",
       "      <th>Cruise</th>\n",
       "      <th>Program</th>\n",
       "      <th>Project</th>\n",
       "      <th>Agency</th>\n",
       "      <th>Source</th>\n",
       "      <th>Station</th>\n",
       "      <th>SampleDate</th>\n",
       "      <th>...</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Method</th>\n",
       "      <th>Lab</th>\n",
       "      <th>Problem</th>\n",
       "      <th>PrecisionPC</th>\n",
       "      <th>BiasPC</th>\n",
       "      <th>Details</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>TierLevel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CB1.0</td>\n",
       "      <td>99182.0</td>\n",
       "      <td>BAY500</td>\n",
       "      <td>TWQM</td>\n",
       "      <td>TRIB</td>\n",
       "      <td>MDDNR</td>\n",
       "      <td>MDDNR</td>\n",
       "      <td>CB1.0</td>\n",
       "      <td>3/4/2009</td>\n",
       "      <td>...</td>\n",
       "      <td>UG/L</td>\n",
       "      <td>L01</td>\n",
       "      <td>MDHMH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.65622</td>\n",
       "      <td>-76.17504</td>\n",
       "      <td>T3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CB1.0</td>\n",
       "      <td>99182.0</td>\n",
       "      <td>BAY500</td>\n",
       "      <td>TWQM</td>\n",
       "      <td>TRIB</td>\n",
       "      <td>MDDNR</td>\n",
       "      <td>MDDNR</td>\n",
       "      <td>CB1.0</td>\n",
       "      <td>3/4/2009</td>\n",
       "      <td>...</td>\n",
       "      <td>UG/L</td>\n",
       "      <td>L01</td>\n",
       "      <td>MDHMH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.65622</td>\n",
       "      <td>-76.17504</td>\n",
       "      <td>T3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CB1.0</td>\n",
       "      <td>99598.0</td>\n",
       "      <td>BAY502</td>\n",
       "      <td>TWQM</td>\n",
       "      <td>TRIB</td>\n",
       "      <td>MDDNR</td>\n",
       "      <td>MDDNR</td>\n",
       "      <td>CB1.0</td>\n",
       "      <td>4/6/2009</td>\n",
       "      <td>...</td>\n",
       "      <td>UG/L</td>\n",
       "      <td>L01</td>\n",
       "      <td>MDHMH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.65622</td>\n",
       "      <td>-76.17504</td>\n",
       "      <td>T3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CB1.0</td>\n",
       "      <td>99598.0</td>\n",
       "      <td>BAY502</td>\n",
       "      <td>TWQM</td>\n",
       "      <td>TRIB</td>\n",
       "      <td>MDDNR</td>\n",
       "      <td>MDDNR</td>\n",
       "      <td>CB1.0</td>\n",
       "      <td>4/6/2009</td>\n",
       "      <td>...</td>\n",
       "      <td>UG/L</td>\n",
       "      <td>L01</td>\n",
       "      <td>MDHMH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.65622</td>\n",
       "      <td>-76.17504</td>\n",
       "      <td>T3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CB1.0</td>\n",
       "      <td>100147.0</td>\n",
       "      <td>BAY504</td>\n",
       "      <td>TWQM</td>\n",
       "      <td>TRIB</td>\n",
       "      <td>MDDNR</td>\n",
       "      <td>MDDNR</td>\n",
       "      <td>CB1.0</td>\n",
       "      <td>5/5/2009</td>\n",
       "      <td>...</td>\n",
       "      <td>UG/L</td>\n",
       "      <td>L01</td>\n",
       "      <td>MDHMH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.65622</td>\n",
       "      <td>-76.17504</td>\n",
       "      <td>T3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 MonitoringStation   EventId  Cruise Program Project Agency  \\\n",
       "0           0             CB1.0   99182.0  BAY500    TWQM    TRIB  MDDNR   \n",
       "1           1             CB1.0   99182.0  BAY500    TWQM    TRIB  MDDNR   \n",
       "2           2             CB1.0   99598.0  BAY502    TWQM    TRIB  MDDNR   \n",
       "3           3             CB1.0   99598.0  BAY502    TWQM    TRIB  MDDNR   \n",
       "4           4             CB1.0  100147.0  BAY504    TWQM    TRIB  MDDNR   \n",
       "\n",
       "  Source Station SampleDate  ...  Unit  Method    Lab  Problem  PrecisionPC  \\\n",
       "0  MDDNR   CB1.0   3/4/2009  ...  UG/L    L01   MDHMH      NaN          NaN   \n",
       "1  MDDNR   CB1.0   3/4/2009  ...  UG/L    L01   MDHMH      NaN          NaN   \n",
       "2  MDDNR   CB1.0   4/6/2009  ...  UG/L    L01   MDHMH      NaN          NaN   \n",
       "3  MDDNR   CB1.0   4/6/2009  ...  UG/L    L01   MDHMH      NaN          NaN   \n",
       "4  MDDNR   CB1.0   5/5/2009  ...  UG/L    L01   MDHMH      NaN          NaN   \n",
       "\n",
       "  BiasPC Details  Latitude Longitude TierLevel  \n",
       "0    NaN     NaN  39.65622 -76.17504        T3  \n",
       "1    NaN     NaN  39.65622 -76.17504        T3  \n",
       "2    NaN     NaN  39.65622 -76.17504        T3  \n",
       "3    NaN     NaN  39.65622 -76.17504        T3  \n",
       "4    NaN     NaN  39.65622 -76.17504        T3  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists(\"data/all_data.csv\"):\n",
    "    print(\"does not exist\")\n",
    "    all_data = pd.read_csv(\"data/station_0_3.csv\")\n",
    "    for i in range(3, 93, 3):\n",
    "        try:\n",
    "            cur_csv = pd.read_csv(f\"data/station_{i}_{i+3}.csv\")\n",
    "        except:\n",
    "            if i == 90:\n",
    "                cur_csv = pd.read_csv(f\"data/station_90_91.csv\")\n",
    "                print(\"last\\n\")\n",
    "            else:\n",
    "                continue\n",
    "        all_data = pd.concat([all_data, cur_csv])\n",
    "    all_data.to_csv(\"data/all_data.csv\")\n",
    "else:\n",
    "    print(\"exists\")\n",
    "    all_data_original = pd.read_csv(\"data/all_data.csv\")\n",
    "all_data_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e66b5b1-538e-4549-b8a1-fe4c6cbdb5bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'MonitoringStation', 'EventId', 'Cruise', 'Program',\n",
       "       'Project', 'Agency', 'Source', 'Station', 'SampleDate', 'SampleTime',\n",
       "       'TotalDepth', 'UpperPycnocline', 'LowerPycnocline', 'Depth', 'Layer',\n",
       "       'SampleType', 'SampleReplicateType', 'Parameter', 'Qualifier',\n",
       "       'MeasureValue', 'Unit', 'Method', 'Lab', 'Problem', 'PrecisionPC',\n",
       "       'BiasPC', 'Details', 'Latitude', 'Longitude', 'TierLevel'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_original.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347d59df-536f-450c-b0db-01242362746b",
   "metadata": {},
   "source": [
    "#### Some columns are not needed and can removed, these columns include:\n",
    "* Details: We don't need the the details columns as we have no Use for this columns, and it is mostly filled with NAN values.\n",
    "* PrecisionPC: Is mostly NAN, hard to find a good metric for when the precision of the value is to low so the value should be thrown out.\n",
    "* BiasPC: Same as PrecisionPC.\n",
    "* Method: We don't really care about the method the labatory did for this project it is outside of this scope and we will not be comparing methods so to save compute and memory we will remove it.\n",
    "* Lab: We don't really care about the lab that did this project it is oustide of the scope of the project to compare the different labs or measure their accuracy we are going to have a base level of trust for all data and labs and will return here if we find low accuracies later on.\n",
    "* Agency, Program, Project, Cruise, EventId: None of these are within the scope of the projet and will be removed as columns from the dataset to save on compute and memory.\n",
    "* TierLevel: This is for quality assurance, and while helpful for determining if it should be used in reports, for this project we are going to assume that all of the data is trustworthy and do not care if exact procedures were taken to get a T1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6bfa750-6465-411d-99e8-e3cf2b3350d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>MonitoringStation</th>\n",
       "      <th>Source</th>\n",
       "      <th>Station</th>\n",
       "      <th>SampleDate</th>\n",
       "      <th>SampleTime</th>\n",
       "      <th>TotalDepth</th>\n",
       "      <th>UpperPycnocline</th>\n",
       "      <th>LowerPycnocline</th>\n",
       "      <th>Depth</th>\n",
       "      <th>Layer</th>\n",
       "      <th>SampleType</th>\n",
       "      <th>SampleReplicateType</th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Qualifier</th>\n",
       "      <th>MeasureValue</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Problem</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CB1.0</td>\n",
       "      <td>MDDNR</td>\n",
       "      <td>CB1.0</td>\n",
       "      <td>3/4/2009</td>\n",
       "      <td>09:26:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "      <td>D</td>\n",
       "      <td>FS1</td>\n",
       "      <td>CHLA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.03</td>\n",
       "      <td>UG/L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.65622</td>\n",
       "      <td>-76.17504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CB1.0</td>\n",
       "      <td>MDDNR</td>\n",
       "      <td>CB1.0</td>\n",
       "      <td>3/4/2009</td>\n",
       "      <td>09:26:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "      <td>D</td>\n",
       "      <td>FS2</td>\n",
       "      <td>CHLA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.03</td>\n",
       "      <td>UG/L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.65622</td>\n",
       "      <td>-76.17504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CB1.0</td>\n",
       "      <td>MDDNR</td>\n",
       "      <td>CB1.0</td>\n",
       "      <td>4/6/2009</td>\n",
       "      <td>09:55:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "      <td>D</td>\n",
       "      <td>FS1</td>\n",
       "      <td>CHLA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.73</td>\n",
       "      <td>UG/L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.65622</td>\n",
       "      <td>-76.17504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CB1.0</td>\n",
       "      <td>MDDNR</td>\n",
       "      <td>CB1.0</td>\n",
       "      <td>4/6/2009</td>\n",
       "      <td>09:55:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "      <td>D</td>\n",
       "      <td>FS2</td>\n",
       "      <td>CHLA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.94</td>\n",
       "      <td>UG/L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.65622</td>\n",
       "      <td>-76.17504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CB1.0</td>\n",
       "      <td>MDDNR</td>\n",
       "      <td>CB1.0</td>\n",
       "      <td>5/5/2009</td>\n",
       "      <td>10:32:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "      <td>D</td>\n",
       "      <td>FS1</td>\n",
       "      <td>CHLA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.75</td>\n",
       "      <td>UG/L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.65622</td>\n",
       "      <td>-76.17504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index MonitoringStation Source Station SampleDate SampleTime  TotalDepth  \\\n",
       "0      0             CB1.0  MDDNR   CB1.0   3/4/2009   09:26:00         NaN   \n",
       "1      1             CB1.0  MDDNR   CB1.0   3/4/2009   09:26:00         NaN   \n",
       "2      2             CB1.0  MDDNR   CB1.0   4/6/2009   09:55:00         NaN   \n",
       "3      3             CB1.0  MDDNR   CB1.0   4/6/2009   09:55:00         NaN   \n",
       "4      4             CB1.0  MDDNR   CB1.0   5/5/2009   10:32:00         NaN   \n",
       "\n",
       "   UpperPycnocline  LowerPycnocline  Depth Layer SampleType  \\\n",
       "0              NaN              NaN    0.0    S           D   \n",
       "1              NaN              NaN    0.0    S           D   \n",
       "2              NaN              NaN    0.0    S           D   \n",
       "3              NaN              NaN    0.0    S           D   \n",
       "4              NaN              NaN    0.0    S           D   \n",
       "\n",
       "  SampleReplicateType Parameter Qualifier  MeasureValue  Unit Problem  \\\n",
       "0                 FS1      CHLA       NaN          2.03  UG/L     NaN   \n",
       "1                 FS2      CHLA       NaN          2.03  UG/L     NaN   \n",
       "2                 FS1      CHLA       NaN         17.73  UG/L     NaN   \n",
       "3                 FS2      CHLA       NaN         17.94  UG/L     NaN   \n",
       "4                 FS1      CHLA       NaN         11.75  UG/L     NaN   \n",
       "\n",
       "   Latitude  Longitude  \n",
       "0  39.65622  -76.17504  \n",
       "1  39.65622  -76.17504  \n",
       "2  39.65622  -76.17504  \n",
       "3  39.65622  -76.17504  \n",
       "4  39.65622  -76.17504  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = all_data_original.drop(columns=['Details', 'PrecisionPC', 'BiasPC', 'Method', 'Lab', 'Agency', 'TierLevel', 'Program', 'Project', 'Cruise', 'EventId'])\n",
    "all_data.rename(columns={'Unnamed: 0': \"index\"}, inplace = True)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55c72484-6e9c-45f8-8efc-c784728364cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows that are duplicates (subsequent occurrences):\n",
      "111226          0\n",
      "111227          1\n",
      "111228          2\n",
      "111229          3\n",
      "111230          4\n",
      "            ...  \n",
      "5067310    109613\n",
      "5067311    109614\n",
      "5067312    109615\n",
      "5067313    109616\n",
      "5067314    109617\n",
      "Name: index, Length: 4688026, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "duplicate_mask = all_data['index'].duplicated()\n",
    "\n",
    "# Print only the rows that are duplicates (subsequent occurrences)\n",
    "print(\"Rows that are duplicates (subsequent occurrences):\")\n",
    "print(all_data['index'][duplicate_mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13b4772-5f44-4786-881c-24525865192b",
   "metadata": {},
   "source": [
    "### Explore Data Shape, Types, NAN values, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f527654-111b-4ec3-a797-a39e5d2bdf46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5067315, 20)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2887f5f-5340-4ec4-a194-4ca343e08c07",
   "metadata": {},
   "source": [
    "#### Find an NAN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac5972dd-2d15-4ae9-963f-b5bd472b660b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                  False\n",
       "MonitoringStation      False\n",
       "Source                  True\n",
       "Station                 True\n",
       "SampleDate              True\n",
       "SampleTime              True\n",
       "TotalDepth              True\n",
       "UpperPycnocline         True\n",
       "LowerPycnocline         True\n",
       "Depth                   True\n",
       "Layer                   True\n",
       "SampleType              True\n",
       "SampleReplicateType     True\n",
       "Parameter               True\n",
       "Qualifier               True\n",
       "MeasureValue            True\n",
       "Unit                    True\n",
       "Problem                 True\n",
       "Latitude                True\n",
       "Longitude               True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.isna().any() #Every Column has NA values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5787e517-64ce-4335-bfcc-674df5f73fb6",
   "metadata": {},
   "source": [
    "#### Columns that should not have Null/NAN values:\n",
    "* Latitude: We need to know where the data came from.\n",
    "* Longitude: We need to know where the data came from.\n",
    "* Unit: We need to knwo what unit it is collected in, if this is missing the data is invalidated.\n",
    "* Parameter: We need to know what data this row is measuring.\n",
    "* MeasureValue: Their should be an actual value that we can use, if this is missing the row is useless to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2ae279f-6c13-4423-a1fe-3141f86bcebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We lost 24909 rows from the original dataframe. We have 5042406 remaining.\n"
     ]
    }
   ],
   "source": [
    "all_data_drop_na = all_data.dropna(subset=['Latitude', 'Longitude', 'Parameter', 'Unit', 'MeasureValue'])\n",
    "print(f\"We lost {all_data.shape[0] - all_data_drop_na.shape[0]} rows from the original dataframe. We have {all_data_drop_na.shape[0]} remaining.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307732a0-5075-457f-969f-b39bad0e2842",
   "metadata": {},
   "source": [
    "#### Now I would like to create seperate columns for every paramter, this will make each parameter a feature that we can use to analyze the data easier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a8f642f-342e-4258-b05a-78c1c47bf334",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Index contains duplicate entries, cannot reshape",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mall_data_drop_na\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpivot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mindex\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mMeasureValue\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mParameter\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/machine_learning/learn-ml-by-building/.venv/lib/python3.12/site-packages/pandas/core/frame.py:9346\u001b[39m, in \u001b[36mDataFrame.pivot\u001b[39m\u001b[34m(self, columns, index, values)\u001b[39m\n\u001b[32m   9339\u001b[39m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   9340\u001b[39m \u001b[38;5;129m@Appender\u001b[39m(_shared_docs[\u001b[33m\"\u001b[39m\u001b[33mpivot\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   9341\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpivot\u001b[39m(\n\u001b[32m   9342\u001b[39m     \u001b[38;5;28mself\u001b[39m, *, columns, index=lib.no_default, values=lib.no_default\n\u001b[32m   9343\u001b[39m ) -> DataFrame:\n\u001b[32m   9344\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreshape\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpivot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pivot\n\u001b[32m-> \u001b[39m\u001b[32m9346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpivot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/machine_learning/learn-ml-by-building/.venv/lib/python3.12/site-packages/pandas/core/reshape/pivot.py:570\u001b[39m, in \u001b[36mpivot\u001b[39m\u001b[34m(data, columns, index, values)\u001b[39m\n\u001b[32m    566\u001b[39m         indexed = data._constructor_sliced(data[values]._values, index=multiindex)\n\u001b[32m    567\u001b[39m \u001b[38;5;66;03m# error: Argument 1 to \"unstack\" of \"DataFrame\" has incompatible type \"Union\u001b[39;00m\n\u001b[32m    568\u001b[39m \u001b[38;5;66;03m# [List[Any], ExtensionArray, ndarray[Any, Any], Index, Series]\"; expected\u001b[39;00m\n\u001b[32m    569\u001b[39m \u001b[38;5;66;03m# \"Hashable\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m570\u001b[39m result = \u001b[43mindexed\u001b[49m\u001b[43m.\u001b[49m\u001b[43munstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns_listlike\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    571\u001b[39m result.index.names = [\n\u001b[32m    572\u001b[39m     name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib.no_default \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m result.index.names\n\u001b[32m    573\u001b[39m ]\n\u001b[32m    575\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/machine_learning/learn-ml-by-building/.venv/lib/python3.12/site-packages/pandas/core/series.py:4626\u001b[39m, in \u001b[36mSeries.unstack\u001b[39m\u001b[34m(self, level, fill_value, sort)\u001b[39m\n\u001b[32m   4581\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4582\u001b[39m \u001b[33;03mUnstack, also known as pivot, Series with MultiIndex to produce DataFrame.\u001b[39;00m\n\u001b[32m   4583\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4622\u001b[39m \u001b[33;03mb    2    4\u001b[39;00m\n\u001b[32m   4623\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4624\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreshape\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreshape\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m unstack\n\u001b[32m-> \u001b[39m\u001b[32m4626\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munstack\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/machine_learning/learn-ml-by-building/.venv/lib/python3.12/site-packages/pandas/core/reshape/reshape.py:517\u001b[39m, in \u001b[36munstack\u001b[39m\u001b[34m(obj, level, fill_value, sort)\u001b[39m\n\u001b[32m    515\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_1d_only_ea_dtype(obj.dtype):\n\u001b[32m    516\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _unstack_extension_series(obj, level, fill_value, sort=sort)\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m unstacker = \u001b[43m_Unstacker\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstructor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_constructor_expanddim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m unstacker.get_result(\n\u001b[32m    521\u001b[39m     obj._values, value_columns=\u001b[38;5;28;01mNone\u001b[39;00m, fill_value=fill_value\n\u001b[32m    522\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/machine_learning/learn-ml-by-building/.venv/lib/python3.12/site-packages/pandas/core/reshape/reshape.py:154\u001b[39m, in \u001b[36m_Unstacker.__init__\u001b[39m\u001b[34m(self, index, level, constructor, sort)\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_cells > np.iinfo(np.int32).max:\n\u001b[32m    147\u001b[39m     warnings.warn(\n\u001b[32m    148\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe following operation may generate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_cells\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m cells \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    149\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33min the resulting pandas object.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    150\u001b[39m         PerformanceWarning,\n\u001b[32m    151\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    152\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_selectors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/machine_learning/learn-ml-by-building/.venv/lib/python3.12/site-packages/pandas/core/reshape/reshape.py:210\u001b[39m, in \u001b[36m_Unstacker._make_selectors\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    207\u001b[39m mask.put(selector, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.sum() < \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.index):\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mIndex contains duplicate entries, cannot reshape\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    212\u001b[39m \u001b[38;5;28mself\u001b[39m.group_index = comp_index\n\u001b[32m    213\u001b[39m \u001b[38;5;28mself\u001b[39m.mask = mask\n",
      "\u001b[31mValueError\u001b[39m: Index contains duplicate entries, cannot reshape"
     ]
    }
   ],
   "source": [
    "all_data_drop_na.pivot(index='index', values='MeasureValue', columns=['Parameter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bb42e4-68d2-45ca-91c7-19ebadb3cb8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
